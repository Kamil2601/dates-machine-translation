{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils import load_dataset, SpecialTokens\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 31385.40it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 28430.56it/s]\n"
     ]
    }
   ],
   "source": [
    "train_size = 10000\n",
    "val_size = 1000\n",
    "train_data, human_vocab, machine_vocab = load_dataset(train_size)\n",
    "val_data, _, _ = load_dataset(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{';': 0,\n",
       " '?': 1,\n",
       " ' ': 2,\n",
       " '.': 3,\n",
       " '/': 4,\n",
       " '0': 5,\n",
       " '1': 6,\n",
       " '2': 7,\n",
       " '3': 8,\n",
       " '4': 9,\n",
       " '5': 10,\n",
       " '6': 11,\n",
       " '7': 12,\n",
       " '8': 13,\n",
       " '9': 14,\n",
       " 'a': 15,\n",
       " 'b': 16,\n",
       " 'c': 17,\n",
       " 'd': 18,\n",
       " 'e': 19,\n",
       " 'f': 20,\n",
       " 'g': 21,\n",
       " 'h': 22,\n",
       " 'i': 23,\n",
       " 'j': 24,\n",
       " 'l': 25,\n",
       " 'm': 26,\n",
       " 'n': 27,\n",
       " 'o': 28,\n",
       " 'p': 29,\n",
       " 'r': 30,\n",
       " 's': 31,\n",
       " 't': 32,\n",
       " 'u': 33,\n",
       " 'v': 34,\n",
       " 'w': 35,\n",
       " 'y': 36}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{';': 0,\n",
       " '>': 1,\n",
       " '<': 2,\n",
       " '-': 3,\n",
       " '0': 4,\n",
       " '1': 5,\n",
       " '2': 6,\n",
       " '3': 7,\n",
       " '4': 8,\n",
       " '5': 9,\n",
       " '6': 10,\n",
       " '7': 11,\n",
       " '8': 12,\n",
       " '9': 13}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3/1/74', '>1974-03-01<'),\n",
       " ('1/7/99', '>1999-01-07<'),\n",
       " ('1/3/95', '>1995-01-03<'),\n",
       " ('5/3/93', '>1993-05-03<'),\n",
       " ('6/1/16', '>2016-06-01<'),\n",
       " ('5/3/83', '>1983-05-03<'),\n",
       " ('9/8/79', '>1979-09-08<'),\n",
       " ('2/5/02', '>2002-02-05<'),\n",
       " ('5/5/05', '>2005-05-05<'),\n",
       " ('2/1/72', '>1972-02-01<'),\n",
       " ('2/7/71', '>1971-02-07<'),\n",
       " ('9/1/74', '>1974-09-01<'),\n",
       " ('5/8/94', '>1994-05-08<'),\n",
       " ('8/7/82', '>1982-08-07<'),\n",
       " ('1/4/86', '>1986-01-04<'),\n",
       " ('5/1/07', '>2007-05-01<'),\n",
       " ('3/9/93', '>1993-03-09<'),\n",
       " ('2/2/84', '>1984-02-02<'),\n",
       " ('3/9/75', '>1975-03-09<'),\n",
       " ('9/8/21', '>2021-09-08<')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1/7/14', '>2014-01-07<'),\n",
       " ('5/7/73', '>1973-05-07<'),\n",
       " ('5/7/20', '>2020-05-07<'),\n",
       " ('5/6/83', '>1983-05-06<'),\n",
       " ('1/1/15', '>2015-01-01<'),\n",
       " ('2/3/70', '>1970-02-03<'),\n",
       " ('4/6/85', '>1985-04-06<'),\n",
       " ('3/4/73', '>1973-03-04<'),\n",
       " ('8/9/09', '>2009-08-09<'),\n",
       " ('1/19/15', '>2015-01-19<'),\n",
       " ('2/12/08', '>2008-02-12<'),\n",
       " ('2 06 70', '>1970-06-02<'),\n",
       " ('1/12/13', '>2013-01-12<'),\n",
       " ('2 10 72', '>1972-10-02<'),\n",
       " ('10/5/14', '>2014-10-05<'),\n",
       " ('6 11 10', '>2010-11-06<'),\n",
       " ('3/19/86', '>1986-03-19<'),\n",
       " ('3 01 04', '>2004-01-03<'),\n",
       " ('5/15/99', '>1999-05-15<'),\n",
       " ('1/31/06', '>2006-01-31<')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def _get_char(self, ind):\n",
    "        if isinstance(ind, torch.Tensor):\n",
    "            return self.inv_vocab[ind.item()]\n",
    "        else:\n",
    "            return self.inv_vocab[ind]\n",
    "\n",
    "    def __init__(self, vocab: dict):\n",
    "        self.vocab = vocab\n",
    "        self.inv_vocab = {v:k for k,v in vocab.items()}\n",
    "        self.vocab_size = len(vocab)\n",
    "\n",
    "    def str_to_ind(self, str):\n",
    "        return [self.vocab[c] for c in str]\n",
    "    \n",
    "    def ind_to_str(self, ind):\n",
    "        return ''.join([self._get_char(i) for i in ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/1/74\n",
      "[8, 4, 6, 4, 12, 9]\n",
      "3/1/74\n"
     ]
    }
   ],
   "source": [
    "test = Lang(human_vocab)\n",
    "date = train_data[0][0]\n",
    "print(date)\n",
    "translated_date = test.str_to_ind(date)\n",
    "print(translated_date)\n",
    "reversed_translation = test.ind_to_str(translated_date)\n",
    "print(reversed_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationTrainingDataset(Dataset):\n",
    "    def __init__(self, data, input_vocab, output_vocab):\n",
    "        self.input_lang = Lang(input_vocab)\n",
    "        self.target_lang = Lang(output_vocab)\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "        self.encoder_inputs = [self.input_lang.str_to_ind(input_sent) for input_sent, _ in self.data]\n",
    "\n",
    "        targets = [self.target_lang.str_to_ind(target_sent) for _, target_sent in self.data]\n",
    "        self.decoder_inputs = [target[:-1] for target in targets]\n",
    "        self.decoder_targets = [target[1:] for target in targets]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoder_inputs[index], self.decoder_inputs[index], self.decoder_targets[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encoder_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TranslationTrainingDataset(train_data, human_vocab, machine_vocab)\n",
    "val_dataset = TranslationTrainingDataset(val_data, human_vocab, machine_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 4, 6, 4, 12, 9] 3/1/74\n",
      "[1, 5, 13, 11, 8, 3, 4, 7, 3, 4, 5] >1974-03-01\n",
      "[5, 13, 11, 8, 3, 4, 7, 3, 4, 5, 2] 1974-03-01<\n"
     ]
    }
   ],
   "source": [
    "x,y,z = train_dataset[0]\n",
    "print(x, train_dataset.input_lang.ind_to_str(x))\n",
    "print(y, train_dataset.target_lang.ind_to_str(y))\n",
    "print(z, train_dataset.target_lang.ind_to_str(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(data):\n",
    "    batch = []\n",
    "    for i in range(len(data[0])):\n",
    "        batch_data = [torch.tensor(item[i], dtype=torch.int64) for item in data]\n",
    "        batch_data = nn.utils.rnn.pad_sequence(batch_data, batch_first=True)\n",
    "        batch.append(batch_data)\n",
    "\n",
    "\n",
    "    return tuple(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, collate_fn=collate_batch, batch_size = 64, num_workers = 8)\n",
    "val_loader = DataLoader(dataset=val_dataset, collate_fn=collate_batch, batch_size = 64, num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers=1, bidirectional=False):\n",
    "        super(EncoderGRU, self).__init__()\n",
    "        self.D = 2 if bidirectional else 1\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(\n",
    "            vocab_size,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        if hidden == None:\n",
    "            hidden = self.init_hidden(x.shape[0]).to(x.device)\n",
    "\n",
    "        one_hot = F.one_hot(x, num_classes=self.vocab_size).float().to(x.device)\n",
    "\n",
    "        output, hidden = self.gru(one_hot, hidden)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(\n",
    "            self.D * self.gru.num_layers,\n",
    "            batch_size,\n",
    "            self.hidden_size,\n",
    "            dtype=torch.float32,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8,  4,  6,  4, 12,  9],\n",
      "        [ 6,  4, 12,  4, 14, 14],\n",
      "        [ 6,  4,  8,  4, 14, 10],\n",
      "        [10,  4,  8,  4, 14,  8],\n",
      "        [11,  4,  6,  4,  6, 11],\n",
      "        [10,  4,  8,  4, 13,  8],\n",
      "        [14,  4, 13,  4, 12, 14],\n",
      "        [ 7,  4, 10,  4,  5,  7],\n",
      "        [10,  4, 10,  4,  5, 10],\n",
      "        [ 7,  4,  6,  4, 12,  7],\n",
      "        [ 7,  4, 12,  4, 12,  6],\n",
      "        [14,  4,  6,  4, 12,  9],\n",
      "        [10,  4, 13,  4, 14,  9],\n",
      "        [13,  4, 12,  4, 13,  7],\n",
      "        [ 6,  4,  9,  4, 13, 11],\n",
      "        [10,  4,  6,  4,  5, 12],\n",
      "        [ 8,  4, 14,  4, 14,  8],\n",
      "        [ 7,  4,  7,  4, 13,  9],\n",
      "        [ 8,  4, 14,  4, 12, 10],\n",
      "        [14,  4, 13,  4,  7,  6],\n",
      "        [14,  4, 13,  4,  5, 14],\n",
      "        [ 7,  4, 11,  4, 12, 12],\n",
      "        [14,  4,  9,  4, 14, 10],\n",
      "        [11,  4, 11,  4, 14,  5],\n",
      "        [13,  4,  8,  4, 13, 10],\n",
      "        [ 7,  4,  9,  4,  5, 10],\n",
      "        [12,  4,  9,  4, 13,  7],\n",
      "        [13,  4, 14,  4,  6,  6],\n",
      "        [ 9,  4, 14,  4,  6,  7],\n",
      "        [11,  4, 13,  4, 12, 13],\n",
      "        [13,  4, 13,  4,  7,  7],\n",
      "        [ 7,  4, 11,  4, 12,  6],\n",
      "        [12,  4, 13,  4, 12,  6],\n",
      "        [13,  4,  9,  4,  6, 11],\n",
      "        [ 7,  4,  8,  4, 12, 14],\n",
      "        [11,  4, 12,  4,  6, 11],\n",
      "        [ 8,  4,  8,  4, 13,  5],\n",
      "        [14,  4, 13,  4,  5,  6],\n",
      "        [ 9,  4,  7,  4,  5, 11],\n",
      "        [14,  4,  8,  4,  6,  8],\n",
      "        [ 6,  4, 13,  4, 12, 14],\n",
      "        [ 6,  4, 14,  4,  5,  8],\n",
      "        [13,  4, 13,  4, 14,  7],\n",
      "        [11,  4,  8,  4,  5, 13],\n",
      "        [ 6,  4, 12,  4, 14,  5],\n",
      "        [ 8,  4,  9,  4, 14,  9],\n",
      "        [13,  4, 13,  4, 13, 11],\n",
      "        [ 8,  4, 13,  4, 14,  6],\n",
      "        [13,  4,  7,  4, 14,  6],\n",
      "        [ 7,  4, 11,  4, 14,  6],\n",
      "        [14,  4,  9,  4, 14,  9],\n",
      "        [ 7,  4, 12,  4,  6, 14],\n",
      "        [14,  4,  8,  4, 14, 14],\n",
      "        [14,  4,  7,  4, 14, 11],\n",
      "        [ 7,  4,  6,  4, 13, 13],\n",
      "        [ 8,  4, 14,  4, 12,  9],\n",
      "        [ 7,  4, 13,  4,  5, 12],\n",
      "        [12,  4,  9,  4, 12, 11],\n",
      "        [13,  4,  8,  4,  5, 14],\n",
      "        [ 8,  4, 10,  4, 12,  7],\n",
      "        [13,  4,  6,  4, 13,  5],\n",
      "        [ 8,  4, 11,  4,  6,  7],\n",
      "        [ 8,  4,  6,  4, 14,  6],\n",
      "        [11,  4,  7,  4,  7,  6]])\n",
      "tensor([[ 1,  5, 13, 11,  8,  3,  4,  7,  3,  4,  5],\n",
      "        [ 1,  5, 13, 13, 13,  3,  4,  5,  3,  4, 11],\n",
      "        [ 1,  5, 13, 13,  9,  3,  4,  5,  3,  4,  7],\n",
      "        [ 1,  5, 13, 13,  7,  3,  4,  9,  3,  4,  7],\n",
      "        [ 1,  6,  4,  5, 10,  3,  4, 10,  3,  4,  5],\n",
      "        [ 1,  5, 13, 12,  7,  3,  4,  9,  3,  4,  7],\n",
      "        [ 1,  5, 13, 11, 13,  3,  4, 13,  3,  4, 12],\n",
      "        [ 1,  6,  4,  4,  6,  3,  4,  6,  3,  4,  9],\n",
      "        [ 1,  6,  4,  4,  9,  3,  4,  9,  3,  4,  9],\n",
      "        [ 1,  5, 13, 11,  6,  3,  4,  6,  3,  4,  5],\n",
      "        [ 1,  5, 13, 11,  5,  3,  4,  6,  3,  4, 11],\n",
      "        [ 1,  5, 13, 11,  8,  3,  4, 13,  3,  4,  5],\n",
      "        [ 1,  5, 13, 13,  8,  3,  4,  9,  3,  4, 12],\n",
      "        [ 1,  5, 13, 12,  6,  3,  4, 12,  3,  4, 11],\n",
      "        [ 1,  5, 13, 12, 10,  3,  4,  5,  3,  4,  8],\n",
      "        [ 1,  6,  4,  4, 11,  3,  4,  9,  3,  4,  5],\n",
      "        [ 1,  5, 13, 13,  7,  3,  4,  7,  3,  4, 13],\n",
      "        [ 1,  5, 13, 12,  8,  3,  4,  6,  3,  4,  6],\n",
      "        [ 1,  5, 13, 11,  9,  3,  4,  7,  3,  4, 13],\n",
      "        [ 1,  6,  4,  6,  5,  3,  4, 13,  3,  4, 12],\n",
      "        [ 1,  6,  4,  4, 13,  3,  4, 13,  3,  4, 12],\n",
      "        [ 1,  5, 13, 11, 11,  3,  4,  6,  3,  4, 10],\n",
      "        [ 1,  5, 13, 13,  9,  3,  4, 13,  3,  4,  8],\n",
      "        [ 1,  5, 13, 13,  4,  3,  4, 10,  3,  4, 10],\n",
      "        [ 1,  5, 13, 12,  9,  3,  4, 12,  3,  4,  7],\n",
      "        [ 1,  6,  4,  4,  9,  3,  4,  6,  3,  4,  8],\n",
      "        [ 1,  5, 13, 12,  6,  3,  4, 11,  3,  4,  8],\n",
      "        [ 1,  6,  4,  5,  5,  3,  4, 12,  3,  4, 13],\n",
      "        [ 1,  6,  4,  5,  6,  3,  4,  8,  3,  4, 13],\n",
      "        [ 1,  5, 13, 11, 12,  3,  4, 10,  3,  4, 12],\n",
      "        [ 1,  6,  4,  6,  6,  3,  4, 12,  3,  4, 12],\n",
      "        [ 1,  5, 13, 11,  5,  3,  4,  6,  3,  4, 10],\n",
      "        [ 1,  5, 13, 11,  5,  3,  4, 11,  3,  4, 12],\n",
      "        [ 1,  6,  4,  5, 10,  3,  4, 12,  3,  4,  8],\n",
      "        [ 1,  5, 13, 11, 13,  3,  4,  6,  3,  4,  7],\n",
      "        [ 1,  6,  4,  5, 10,  3,  4, 10,  3,  4, 11],\n",
      "        [ 1,  5, 13, 12,  4,  3,  4,  7,  3,  4,  7],\n",
      "        [ 1,  6,  4,  4,  5,  3,  4, 13,  3,  4, 12],\n",
      "        [ 1,  6,  4,  4, 10,  3,  4,  8,  3,  4,  6],\n",
      "        [ 1,  6,  4,  5,  7,  3,  4, 13,  3,  4,  7],\n",
      "        [ 1,  5, 13, 11, 13,  3,  4,  5,  3,  4, 12],\n",
      "        [ 1,  6,  4,  4,  7,  3,  4,  5,  3,  4, 13],\n",
      "        [ 1,  5, 13, 13,  6,  3,  4, 12,  3,  4, 12],\n",
      "        [ 1,  6,  4,  4, 12,  3,  4, 10,  3,  4,  7],\n",
      "        [ 1,  5, 13, 13,  4,  3,  4,  5,  3,  4, 11],\n",
      "        [ 1,  5, 13, 13,  8,  3,  4,  7,  3,  4,  8],\n",
      "        [ 1,  5, 13, 12, 10,  3,  4, 12,  3,  4, 12],\n",
      "        [ 1,  5, 13, 13,  5,  3,  4,  7,  3,  4, 12],\n",
      "        [ 1,  5, 13, 13,  5,  3,  4, 12,  3,  4,  6],\n",
      "        [ 1,  5, 13, 13,  5,  3,  4,  6,  3,  4, 10],\n",
      "        [ 1,  5, 13, 13,  8,  3,  4, 13,  3,  4,  8],\n",
      "        [ 1,  6,  4,  5, 13,  3,  4,  6,  3,  4, 11],\n",
      "        [ 1,  5, 13, 13, 13,  3,  4, 13,  3,  4,  7],\n",
      "        [ 1,  5, 13, 13, 10,  3,  4, 13,  3,  4,  6],\n",
      "        [ 1,  5, 13, 12, 12,  3,  4,  6,  3,  4,  5],\n",
      "        [ 1,  5, 13, 11,  8,  3,  4,  7,  3,  4, 13],\n",
      "        [ 1,  6,  4,  4, 11,  3,  4,  6,  3,  4, 12],\n",
      "        [ 1,  5, 13, 11, 10,  3,  4, 11,  3,  4,  8],\n",
      "        [ 1,  6,  4,  4, 13,  3,  4, 12,  3,  4,  7],\n",
      "        [ 1,  5, 13, 11,  6,  3,  4,  7,  3,  4,  9],\n",
      "        [ 1,  5, 13, 12,  4,  3,  4, 12,  3,  4,  5],\n",
      "        [ 1,  6,  4,  5,  6,  3,  4,  7,  3,  4, 10],\n",
      "        [ 1,  5, 13, 13,  5,  3,  4,  7,  3,  4,  5],\n",
      "        [ 1,  6,  4,  6,  5,  3,  4, 10,  3,  4,  6]])\n",
      "tensor([[ 5, 13, 11,  8,  3,  4,  7,  3,  4,  5,  2],\n",
      "        [ 5, 13, 13, 13,  3,  4,  5,  3,  4, 11,  2],\n",
      "        [ 5, 13, 13,  9,  3,  4,  5,  3,  4,  7,  2],\n",
      "        [ 5, 13, 13,  7,  3,  4,  9,  3,  4,  7,  2],\n",
      "        [ 6,  4,  5, 10,  3,  4, 10,  3,  4,  5,  2],\n",
      "        [ 5, 13, 12,  7,  3,  4,  9,  3,  4,  7,  2],\n",
      "        [ 5, 13, 11, 13,  3,  4, 13,  3,  4, 12,  2],\n",
      "        [ 6,  4,  4,  6,  3,  4,  6,  3,  4,  9,  2],\n",
      "        [ 6,  4,  4,  9,  3,  4,  9,  3,  4,  9,  2],\n",
      "        [ 5, 13, 11,  6,  3,  4,  6,  3,  4,  5,  2],\n",
      "        [ 5, 13, 11,  5,  3,  4,  6,  3,  4, 11,  2],\n",
      "        [ 5, 13, 11,  8,  3,  4, 13,  3,  4,  5,  2],\n",
      "        [ 5, 13, 13,  8,  3,  4,  9,  3,  4, 12,  2],\n",
      "        [ 5, 13, 12,  6,  3,  4, 12,  3,  4, 11,  2],\n",
      "        [ 5, 13, 12, 10,  3,  4,  5,  3,  4,  8,  2],\n",
      "        [ 6,  4,  4, 11,  3,  4,  9,  3,  4,  5,  2],\n",
      "        [ 5, 13, 13,  7,  3,  4,  7,  3,  4, 13,  2],\n",
      "        [ 5, 13, 12,  8,  3,  4,  6,  3,  4,  6,  2],\n",
      "        [ 5, 13, 11,  9,  3,  4,  7,  3,  4, 13,  2],\n",
      "        [ 6,  4,  6,  5,  3,  4, 13,  3,  4, 12,  2],\n",
      "        [ 6,  4,  4, 13,  3,  4, 13,  3,  4, 12,  2],\n",
      "        [ 5, 13, 11, 11,  3,  4,  6,  3,  4, 10,  2],\n",
      "        [ 5, 13, 13,  9,  3,  4, 13,  3,  4,  8,  2],\n",
      "        [ 5, 13, 13,  4,  3,  4, 10,  3,  4, 10,  2],\n",
      "        [ 5, 13, 12,  9,  3,  4, 12,  3,  4,  7,  2],\n",
      "        [ 6,  4,  4,  9,  3,  4,  6,  3,  4,  8,  2],\n",
      "        [ 5, 13, 12,  6,  3,  4, 11,  3,  4,  8,  2],\n",
      "        [ 6,  4,  5,  5,  3,  4, 12,  3,  4, 13,  2],\n",
      "        [ 6,  4,  5,  6,  3,  4,  8,  3,  4, 13,  2],\n",
      "        [ 5, 13, 11, 12,  3,  4, 10,  3,  4, 12,  2],\n",
      "        [ 6,  4,  6,  6,  3,  4, 12,  3,  4, 12,  2],\n",
      "        [ 5, 13, 11,  5,  3,  4,  6,  3,  4, 10,  2],\n",
      "        [ 5, 13, 11,  5,  3,  4, 11,  3,  4, 12,  2],\n",
      "        [ 6,  4,  5, 10,  3,  4, 12,  3,  4,  8,  2],\n",
      "        [ 5, 13, 11, 13,  3,  4,  6,  3,  4,  7,  2],\n",
      "        [ 6,  4,  5, 10,  3,  4, 10,  3,  4, 11,  2],\n",
      "        [ 5, 13, 12,  4,  3,  4,  7,  3,  4,  7,  2],\n",
      "        [ 6,  4,  4,  5,  3,  4, 13,  3,  4, 12,  2],\n",
      "        [ 6,  4,  4, 10,  3,  4,  8,  3,  4,  6,  2],\n",
      "        [ 6,  4,  5,  7,  3,  4, 13,  3,  4,  7,  2],\n",
      "        [ 5, 13, 11, 13,  3,  4,  5,  3,  4, 12,  2],\n",
      "        [ 6,  4,  4,  7,  3,  4,  5,  3,  4, 13,  2],\n",
      "        [ 5, 13, 13,  6,  3,  4, 12,  3,  4, 12,  2],\n",
      "        [ 6,  4,  4, 12,  3,  4, 10,  3,  4,  7,  2],\n",
      "        [ 5, 13, 13,  4,  3,  4,  5,  3,  4, 11,  2],\n",
      "        [ 5, 13, 13,  8,  3,  4,  7,  3,  4,  8,  2],\n",
      "        [ 5, 13, 12, 10,  3,  4, 12,  3,  4, 12,  2],\n",
      "        [ 5, 13, 13,  5,  3,  4,  7,  3,  4, 12,  2],\n",
      "        [ 5, 13, 13,  5,  3,  4, 12,  3,  4,  6,  2],\n",
      "        [ 5, 13, 13,  5,  3,  4,  6,  3,  4, 10,  2],\n",
      "        [ 5, 13, 13,  8,  3,  4, 13,  3,  4,  8,  2],\n",
      "        [ 6,  4,  5, 13,  3,  4,  6,  3,  4, 11,  2],\n",
      "        [ 5, 13, 13, 13,  3,  4, 13,  3,  4,  7,  2],\n",
      "        [ 5, 13, 13, 10,  3,  4, 13,  3,  4,  6,  2],\n",
      "        [ 5, 13, 12, 12,  3,  4,  6,  3,  4,  5,  2],\n",
      "        [ 5, 13, 11,  8,  3,  4,  7,  3,  4, 13,  2],\n",
      "        [ 6,  4,  4, 11,  3,  4,  6,  3,  4, 12,  2],\n",
      "        [ 5, 13, 11, 10,  3,  4, 11,  3,  4,  8,  2],\n",
      "        [ 6,  4,  4, 13,  3,  4, 12,  3,  4,  7,  2],\n",
      "        [ 5, 13, 11,  6,  3,  4,  7,  3,  4,  9,  2],\n",
      "        [ 5, 13, 12,  4,  3,  4, 12,  3,  4,  5,  2],\n",
      "        [ 6,  4,  5,  6,  3,  4,  7,  3,  4, 10,  2],\n",
      "        [ 5, 13, 13,  5,  3,  4,  7,  3,  4,  5,  2],\n",
      "        [ 6,  4,  6,  5,  3,  4, 10,  3,  4,  6,  2]])\n",
      "EncoderGRU(\n",
      "  (gru): GRU(37, 32, batch_first=True)\n",
      ")\n",
      "torch.Size([64, 6, 32]) torch.Size([1, 64, 32])\n"
     ]
    }
   ],
   "source": [
    "x_enc_batch,  x_dec_batch, y_batch = next(iter(train_loader))\n",
    "print(x_enc_batch)\n",
    "print(x_dec_batch)\n",
    "print(y_batch)\n",
    "encoder = EncoderGRU(len(human_vocab), hidden_size=32, num_layers=1, bidirectional=False)\n",
    "print(encoder)\n",
    "enc_out, enc_hidden = encoder(x_enc_batch)\n",
    "print(enc_out.shape, enc_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/1/74\n",
      "1/7/99\n",
      "1/3/95\n",
      "5/3/93\n",
      "6/1/16\n",
      "5/3/83\n",
      "9/8/79\n",
      "2/5/02\n",
      "5/5/05\n",
      "2/1/72\n",
      "2/7/71\n",
      "9/1/74\n",
      "5/8/94\n",
      "8/7/82\n",
      "1/4/86\n",
      "5/1/07\n",
      "3/9/93\n",
      "2/2/84\n",
      "3/9/75\n",
      "9/8/21\n",
      "9/8/09\n",
      "2/6/77\n",
      "9/4/95\n",
      "6/6/90\n",
      "8/3/85\n",
      "2/4/05\n",
      "7/4/82\n",
      "8/9/11\n",
      "4/9/12\n",
      "6/8/78\n",
      "8/8/22\n",
      "2/6/71\n",
      "7/8/71\n",
      "8/4/16\n",
      "2/3/79\n",
      "6/7/16\n",
      "3/3/80\n",
      "9/8/01\n",
      "4/2/06\n",
      "9/3/13\n",
      "1/8/79\n",
      "1/9/03\n",
      "8/8/92\n",
      "6/3/08\n",
      "1/7/90\n",
      "3/4/94\n",
      "8/8/86\n",
      "3/8/91\n",
      "8/2/91\n",
      "2/6/91\n",
      "9/4/94\n",
      "2/7/19\n",
      "9/3/99\n",
      "9/2/96\n",
      "2/1/88\n",
      "3/9/74\n",
      "2/8/07\n",
      "7/4/76\n",
      "8/3/09\n",
      "3/5/72\n",
      "8/1/80\n",
      "3/6/12\n",
      "3/1/91\n",
      "6/2/21\n"
     ]
    }
   ],
   "source": [
    "lang = train_dataset.input_lang\n",
    "for row in x_enc_batch:\n",
    "    print(lang.ind_to_str(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers=1):\n",
    "        super(DecoderGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(\n",
    "            vocab_size, hidden_size, num_layers=num_layers, batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        if hidden == None:\n",
    "            hidden = self.init_hidden(x.shape[0]).to(x.device)\n",
    "        one_hot = F.one_hot(x, num_classes=self.vocab_size).float().to(x.device)\n",
    "        output, hidden = self.gru(one_hot, hidden)\n",
    "        output = self.fc(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(\n",
    "            self.gru.num_layers, batch_size, self.hidden_size, dtype=torch.float32\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecoderGRU(\n",
      "  (gru): GRU(14, 32, batch_first=True)\n",
      "  (fc): Linear(in_features=32, out_features=14, bias=True)\n",
      ")\n",
      "EncoderGRU(\n",
      "  (gru): GRU(37, 32, batch_first=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderGRU(len(human_vocab), hidden_size=32, num_layers=1, bidirectional=False)\n",
    "decoder = DecoderGRU(len(machine_vocab), hidden_size=32, num_layers=1)\n",
    "print(decoder)\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder forward pass\n",
      "\n",
      "Training with teacher forcing\n",
      "Input batch shape: torch.Size([64, 11])\n",
      "decoder output shape: torch.Size([64, 11, 14])\n",
      "decoder hn shape: torch.Size([1, 64, 32])\n",
      "\n",
      "Training without teacher forcing\n",
      "Decoder 1st input shape: torch.Size([64, 1])\n",
      "decoder output shape: torch.Size([64, 1, 14])\n",
      "decoder hn shape: torch.Size([1, 64, 32])\n",
      "decoder 2nd input shape: torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"Decoder forward pass\\n\")\n",
    "\n",
    "# Teacher forcing\n",
    "print(\"Training with teacher forcing\")\n",
    "print(f\"Input batch shape: {x_dec_batch.shape}\")\n",
    "dec_out, dec_hid = decoder(x_dec_batch, enc_hidden)\n",
    "print(f\"decoder output shape: {dec_out.shape}\\ndecoder hn shape: {dec_hid.shape}\")\n",
    "# loss(dec_out, target)\n",
    "print()\n",
    "# Without teacher forcing\n",
    "print(\"Training without teacher forcing\")\n",
    "dec_input = x_dec_batch[:,0:1]\n",
    "print(f\"Decoder 1st input shape: {dec_input.shape}\")\n",
    "dec_out, dec_hid = decoder(dec_input, enc_hidden)\n",
    "print(f\"decoder output shape: {dec_out.shape}\\ndecoder hn shape: {dec_hid.shape}\")\n",
    "next_input = torch.argmax(dec_out, dim=-1)\n",
    "print(f\"decoder 2nd input shape: {next_input.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2sec(nn.Module):\n",
    "    def __init__(self, encoder, decoder) -> None:\n",
    "        super(Seq2sec, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_input_batch, sos_index = 1, dec_input_batch = None, teacher_forcing = False, out_length = 1):\n",
    "        encoder_output, encoder_hidden = self.encoder(enc_input_batch)\n",
    "        batch_size = len(enc_input_batch)\n",
    "\n",
    "        if teacher_forcing:\n",
    "            decoder_output, _ = self.decoder(dec_input_batch, encoder_hidden)\n",
    "            return decoder_output\n",
    "        else:\n",
    "            decoder_input = (torch.zeros(batch_size, 1, dtype=torch.int64) + sos_index).to(enc_input_batch.device)\n",
    "            decoder_output = torch.empty(batch_size, out_length, self.decoder.vocab_size).to(enc_input_batch.device)\n",
    "\n",
    "            hidden = encoder_hidden\n",
    "\n",
    "            for i in range(out_length):\n",
    "                decoder_output_i, hidden = self.decoder(decoder_input, hidden)\n",
    "                decoder_output[:,i:i+1,:] = decoder_output_i\n",
    "                decoder_input = torch.argmax(decoder_output_i, dim=-1)\n",
    "\n",
    "            return decoder_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2sec(\n",
       "  (encoder): EncoderGRU(\n",
       "    (gru): GRU(37, 32, batch_first=True)\n",
       "  )\n",
       "  (decoder): DecoderGRU(\n",
       "    (gru): GRU(14, 32, batch_first=True)\n",
       "    (fc): Linear(in_features=32, out_features=14, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Seq2sec(encoder, decoder)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20, 14])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_enc_batch, out_length = 20).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 11, 14])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_enc_batch, dec_input_batch = x_dec_batch, teacher_forcing = True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model forward pass (input -> encoder -> decoder -> output)\n",
      "\n",
      "Training without teacher forcing (out_length = 20)\n",
      "Input batch shape: torch.Size([64, 6])\n",
      "Output shape: torch.Size([64, 20, 14])\n",
      "\n",
      "Training with teacher forcing\n",
      "Encoder input batch shape: torch.Size([64, 6])\n",
      "Decoder input batch shape: torch.Size([64, 11])\n",
      "Output shape: torch.Size([64, 11, 14])\n"
     ]
    }
   ],
   "source": [
    "print(\"Model forward pass (input -> encoder -> decoder -> output)\\n\")\n",
    "\n",
    "# Teacher forcing\n",
    "print(\"Training without teacher forcing (out_length = 20)\")\n",
    "print(f\"Input batch shape: {x_enc_batch.shape}\")\n",
    "output =  model(x_enc_batch, out_length = 20)\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "\n",
    "print()\n",
    "# Without teacher forcing\n",
    "print(\"Training with teacher forcing\")\n",
    "print(f\"Encoder input batch shape: {x_enc_batch.shape}\")\n",
    "print(f\"Decoder input batch shape: {x_dec_batch.shape}\")\n",
    "output = model(x_enc_batch, dec_input_batch = x_dec_batch, teacher_forcing = True)\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_dataLoader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        val_dataLoader=None,\n",
    "        padding_index=0,\n",
    "        sos_index=1,\n",
    "        teacher_forcing_ratio=0.5,\n",
    "        device=device,\n",
    "    ) -> None:\n",
    "        self.model = model.to(device)\n",
    "        self.train_dataLoader = train_dataLoader\n",
    "        self.val_dataLoader = val_dataLoader\n",
    "        self.loss_fn = loss_fn\n",
    "        self.padding_index = padding_index\n",
    "        self.sos_index = sos_index\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def loss_value(self, output, target):\n",
    "        C = output.shape[-1]\n",
    "\n",
    "        output_flat = output.view(-1, C)\n",
    "        target_flat = target.view(-1)\n",
    "\n",
    "        loss = self.loss_fn(output_flat, target_flat)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def train_batch(self, encoder_input, decoder_input, target):\n",
    "        teacher_forcing = np.random.random() < self.teacher_forcing_ratio\n",
    "\n",
    "        output = self.model(\n",
    "            encoder_input,\n",
    "            dec_input_batch=decoder_input,\n",
    "            teacher_forcing=teacher_forcing,\n",
    "            sos_index=self.sos_index,\n",
    "            out_length=target.shape[1],\n",
    "        )\n",
    "\n",
    "        loss = self.loss_value(output, target)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    def train_one_epoch(self):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        epoch_loss = 0\n",
    "        batch_losses = []\n",
    "\n",
    "        i = 1\n",
    "\n",
    "        for enc_input, dec_input, target in self.train_dataLoader:\n",
    "            i += 1\n",
    "            enc_input = enc_input.to(self.device)\n",
    "            dec_input = dec_input.to(self.device)\n",
    "            target = target.to(self.device)\n",
    "\n",
    "            batch_loss = self.train_batch(\n",
    "                encoder_input=enc_input, decoder_input=dec_input, target=target\n",
    "            )\n",
    "\n",
    "            epoch_loss += batch_loss * len(enc_input)\n",
    "            batch_losses.append(batch_loss)\n",
    "\n",
    "        size = len(self.train_dataLoader.dataset)\n",
    "\n",
    "        return epoch_loss / size, batch_losses\n",
    "\n",
    "    def validation(self):\n",
    "        size = len(self.val_dataLoader.dataset)\n",
    "        model.eval()\n",
    "\n",
    "        test_loss = 0\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            for enc_input, _, target in self.val_dataLoader:\n",
    "                enc_input = enc_input.to(self.device)\n",
    "                target = target.to(self.device)\n",
    "\n",
    "                out = self.model(\n",
    "                    enc_input,\n",
    "                    teacher_forcing=False,\n",
    "                    sos_index=self.sos_index,\n",
    "                    out_length=target.shape[1],\n",
    "                )\n",
    "                test_loss += self.loss_value(out, target).item() * len(enc_input)\n",
    "\n",
    "            return test_loss / size\n",
    "\n",
    "    def train(self, n_epochs, verbose = True):\n",
    "        for epoch in range(n_epochs):\n",
    "            epoch_loss, batch_losses = self.train_one_epoch()\n",
    "\n",
    "            if self.val_dataLoader != None:\n",
    "                val_loss = self.validation()\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"Epoch {epoch + 1 :< 4}  training loss: {epoch_loss:>8f} | validation loss: {val_loss:>8f}\")\\\n",
    "                    \n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"Epoch {epoch + 1 :< 10}  training loss: {epoch_loss:>8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "cross_entropy_loss = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "trainer = Trainer(model, train_dataLoader=train_loader, val_dataLoader=val_loader, loss_fn= cross_entropy_loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1    training loss: 0.089085 | validation loss: 0.143550\n",
      "Epoch  2    training loss: 0.086851 | validation loss: 0.141181\n",
      "Epoch  3    training loss: 0.082644 | validation loss: 0.137157\n",
      "Epoch  4    training loss: 0.079808 | validation loss: 0.138590\n",
      "Epoch  5    training loss: 0.078739 | validation loss: 0.126426\n",
      "Epoch  6    training loss: 0.074671 | validation loss: 0.129002\n",
      "Epoch  7    training loss: 0.073189 | validation loss: 0.132413\n",
      "Epoch  8    training loss: 0.073589 | validation loss: 0.129050\n",
      "Epoch  9    training loss: 0.074706 | validation loss: 0.144906\n",
      "Epoch  10   training loss: 0.075718 | validation loss: 0.140417\n",
      "Epoch  11   training loss: 0.073115 | validation loss: 0.140514\n",
      "Epoch  12   training loss: 0.072580 | validation loss: 0.136022\n",
      "Epoch  13   training loss: 0.073757 | validation loss: 0.133527\n",
      "Epoch  14   training loss: 0.070386 | validation loss: 0.135001\n",
      "Epoch  15   training loss: 0.067909 | validation loss: 0.132079\n",
      "Epoch  16   training loss: 0.068104 | validation loss: 0.126388\n",
      "Epoch  17   training loss: 0.067706 | validation loss: 0.134366\n",
      "Epoch  18   training loss: 0.067136 | validation loss: 0.129780\n",
      "Epoch  19   training loss: 0.067416 | validation loss: 0.138324\n",
      "Epoch  20   training loss: 0.064884 | validation loss: 0.135547\n",
      "Epoch  21   training loss: 0.066997 | validation loss: 0.125457\n",
      "Epoch  22   training loss: 0.066600 | validation loss: 0.136321\n",
      "Epoch  23   training loss: 0.070592 | validation loss: 0.132879\n",
      "Epoch  24   training loss: 0.068142 | validation loss: 0.135841\n",
      "Epoch  25   training loss: 0.064188 | validation loss: 0.138948\n",
      "Epoch  26   training loss: 0.068925 | validation loss: 0.112560\n",
      "Epoch  27   training loss: 0.069142 | validation loss: 0.096971\n",
      "Epoch  28   training loss: 0.058470 | validation loss: 0.100838\n",
      "Epoch  29   training loss: 0.047878 | validation loss: 0.082924\n",
      "Epoch  30   training loss: 0.045369 | validation loss: 0.080828\n"
     ]
    }
   ],
   "source": [
    "trainer.train(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation test\n",
      "\n",
      "Input                 |   Machine translation | Correct translation\n",
      "thursday november 18 1999 1999-11-18            1999-11-18\n",
      "4 mar 2019                2019-03-04            2019-03-04\n",
      "april 9 2014              2014-04-29            2014-04-09\n",
      "24 aug 1989               1998-08-24            1989-08-24\n",
      "9 march 1982              1998-03-29            1982-03-09\n",
      "sunday september 19 2021  2021-09-05            2021-09-19\n",
      "28 september 2005         2002-09-28            2005-09-28\n",
      "6 february 2016           2016-02-06            2016-02-06\n",
      "sunday september 6 2009   2009-09-06            2009-09-06\n",
      "22 jun 1989               1998-06-22            1989-06-22\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(dataset=val_dataset, collate_fn=collate_batch, batch_size = 64, num_workers = 8, shuffle=True)\n",
    "\n",
    "x, z, y = next(iter(test_loader))\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "z = z.to(device)\n",
    "\n",
    "y_hat = model(\n",
    "        x,\n",
    "        teacher_forcing=False,\n",
    "        sos_index=1,\n",
    "        out_length=11,\n",
    "    )\n",
    "\n",
    "input_lang = train_dataset.input_lang\n",
    "output_lang = train_dataset.target_lang\n",
    "\n",
    "y_hat = y_hat.argmax(axis=-1)\n",
    "\n",
    "print(\"Translation test\\n\")\n",
    "print(\"Input                 |   Machine translation | Correct translation\")\n",
    "for i in range(10):\n",
    "    print(input_lang.ind_to_str(x[i]).replace(';', ' '), output_lang.ind_to_str(y_hat[i]).strip('<>;'), \" \"*10, output_lang.ind_to_str(y[i]).strip(';<>'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
