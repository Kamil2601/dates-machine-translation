{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils import load_dataset, SpecialTokens\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 31128.66it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 33722.23it/s]\n"
     ]
    }
   ],
   "source": [
    "train_size = 10000\n",
    "val_size = 1000\n",
    "train_data, human_vocab, machine_vocab = load_dataset(train_size)\n",
    "val_data, _, _ = load_dataset(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{';': 0,\n",
       " '?': 1,\n",
       " ' ': 2,\n",
       " '.': 3,\n",
       " '/': 4,\n",
       " '0': 5,\n",
       " '1': 6,\n",
       " '2': 7,\n",
       " '3': 8,\n",
       " '4': 9,\n",
       " '5': 10,\n",
       " '6': 11,\n",
       " '7': 12,\n",
       " '8': 13,\n",
       " '9': 14,\n",
       " 'a': 15,\n",
       " 'b': 16,\n",
       " 'c': 17,\n",
       " 'd': 18,\n",
       " 'e': 19,\n",
       " 'f': 20,\n",
       " 'g': 21,\n",
       " 'h': 22,\n",
       " 'i': 23,\n",
       " 'j': 24,\n",
       " 'l': 25,\n",
       " 'm': 26,\n",
       " 'n': 27,\n",
       " 'o': 28,\n",
       " 'p': 29,\n",
       " 'r': 30,\n",
       " 's': 31,\n",
       " 't': 32,\n",
       " 'u': 33,\n",
       " 'v': 34,\n",
       " 'w': 35,\n",
       " 'y': 36}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{';': 0,\n",
       " '>': 1,\n",
       " '<': 2,\n",
       " '-': 3,\n",
       " '0': 4,\n",
       " '1': 5,\n",
       " '2': 6,\n",
       " '3': 7,\n",
       " '4': 8,\n",
       " '5': 9,\n",
       " '6': 10,\n",
       " '7': 11,\n",
       " '8': 12,\n",
       " '9': 13}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('5/8/10', '>2010-05-08<'),\n",
       " ('9/3/72', '>1972-09-03<'),\n",
       " ('5/4/80', '>1980-05-04<'),\n",
       " ('3/7/85', '>1985-03-07<'),\n",
       " ('8/4/80', '>1980-08-04<'),\n",
       " ('5/4/00', '>2000-05-04<'),\n",
       " ('5/4/07', '>2007-05-04<'),\n",
       " ('5/1/78', '>1978-05-01<'),\n",
       " ('2/1/72', '>1972-02-01<'),\n",
       " ('3/6/07', '>2007-03-06<'),\n",
       " ('8/7/11', '>2011-08-07<'),\n",
       " ('3/7/14', '>2014-03-07<'),\n",
       " ('2/3/85', '>1985-02-03<'),\n",
       " ('5/7/83', '>1983-05-07<'),\n",
       " ('6/6/92', '>1992-06-06<'),\n",
       " ('3/4/94', '>1994-03-04<'),\n",
       " ('7/3/74', '>1974-07-03<'),\n",
       " ('1/5/78', '>1978-01-05<'),\n",
       " ('1/5/79', '>1979-01-05<'),\n",
       " ('9/5/07', '>2007-09-05<')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2/8/23', '>2023-02-08<'),\n",
       " ('4/9/07', '>2007-04-09<'),\n",
       " ('5/7/99', '>1999-05-07<'),\n",
       " ('2/9/04', '>2004-02-09<'),\n",
       " ('4/2/92', '>1992-04-02<'),\n",
       " ('12/5/99', '>1999-12-05<'),\n",
       " ('8/18/77', '>1977-08-18<'),\n",
       " ('7 06 16', '>2016-06-07<'),\n",
       " ('7/23/17', '>2017-07-23<'),\n",
       " ('7/15/84', '>1984-07-15<'),\n",
       " ('3/19/86', '>1986-03-19<'),\n",
       " ('4 01 21', '>2021-01-04<'),\n",
       " ('8 02 02', '>2002-02-08<'),\n",
       " ('4/26/94', '>1994-04-26<'),\n",
       " ('7/14/18', '>2018-07-14<'),\n",
       " ('5/25/81', '>1981-05-25<'),\n",
       " ('1/18/80', '>1980-01-18<'),\n",
       " ('8/13/77', '>1977-08-13<'),\n",
       " ('5 10 16', '>2016-10-05<'),\n",
       " ('4/12/94', '>1994-04-12<')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def _get_char(self, ind):\n",
    "        if isinstance(ind, torch.Tensor):\n",
    "            return self.inv_vocab[ind.item()]\n",
    "        else:\n",
    "            return self.inv_vocab[ind]\n",
    "\n",
    "    def __init__(self, vocab: dict):\n",
    "        self.vocab = vocab\n",
    "        self.inv_vocab = {v:k for k,v in vocab.items()}\n",
    "        self.vocab_size = len(vocab)\n",
    "\n",
    "    def str_to_ind(self, str):\n",
    "        return [self.vocab[c] for c in str]\n",
    "    \n",
    "    def ind_to_str(self, ind):\n",
    "        return ''.join([self._get_char(i) for i in ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/8/10\n",
      "[10, 4, 13, 4, 6, 5]\n",
      "5/8/10\n"
     ]
    }
   ],
   "source": [
    "test = Lang(human_vocab)\n",
    "date = train_data[0][0]\n",
    "print(date)\n",
    "translated_date = test.str_to_ind(date)\n",
    "print(translated_date)\n",
    "reversed_translation = test.ind_to_str(translated_date)\n",
    "print(reversed_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationTrainingDataset(Dataset):\n",
    "    def __init__(self, data, input_vocab, output_vocab):\n",
    "        self.input_lang = Lang(input_vocab)\n",
    "        self.target_lang = Lang(output_vocab)\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "        self.encoder_inputs = [self.input_lang.str_to_ind(input_sent) for input_sent, _ in self.data]\n",
    "\n",
    "        targets = [self.target_lang.str_to_ind(target_sent) for _, target_sent in self.data]\n",
    "        self.decoder_inputs = [target[:-1] for target in targets]\n",
    "        self.decoder_targets = [target[1:] for target in targets]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoder_inputs[index], self.decoder_inputs[index], self.decoder_targets[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encoder_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TranslationTrainingDataset(train_data, human_vocab, machine_vocab)\n",
    "val_dataset = TranslationTrainingDataset(val_data, human_vocab, machine_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 4, 13, 4, 6, 5] 5/8/10\n",
      "[1, 6, 4, 5, 4, 3, 4, 9, 3, 4, 12] >2010-05-08\n",
      "[6, 4, 5, 4, 3, 4, 9, 3, 4, 12, 2] 2010-05-08<\n"
     ]
    }
   ],
   "source": [
    "x,y,z = train_dataset[0]\n",
    "print(x, train_dataset.input_lang.ind_to_str(x))\n",
    "print(y, train_dataset.target_lang.ind_to_str(y))\n",
    "print(z, train_dataset.target_lang.ind_to_str(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(data):\n",
    "    batch = []\n",
    "    for i in range(len(data[0])):\n",
    "        batch_data = [torch.tensor(item[i], dtype=torch.int64) for item in data]\n",
    "        batch_data = nn.utils.rnn.pad_sequence(batch_data, batch_first=True)\n",
    "        batch.append(batch_data)\n",
    "\n",
    "\n",
    "    return tuple(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, collate_fn=collate_batch, batch_size = 64, num_workers = 8)\n",
    "val_loader = DataLoader(dataset=val_dataset, collate_fn=collate_batch, batch_size = 64, num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers=1, bidirectional=False):\n",
    "        super(EncoderGRU, self).__init__()\n",
    "        self.D = 2 if bidirectional else 1\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(\n",
    "            vocab_size,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        if hidden == None:\n",
    "            hidden = self.init_hidden(x.shape[0]).to(x.device)\n",
    "\n",
    "        one_hot = F.one_hot(x, num_classes=self.vocab_size).float().to(x.device)\n",
    "\n",
    "        output, hidden = self.gru(one_hot, hidden)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(\n",
    "            self.D * self.gru.num_layers,\n",
    "            batch_size,\n",
    "            self.hidden_size,\n",
    "            dtype=torch.float32,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10,  4, 13,  4,  6,  5],\n",
      "        [14,  4,  8,  4, 12,  7],\n",
      "        [10,  4,  9,  4, 13,  5],\n",
      "        [ 8,  4, 12,  4, 13, 10],\n",
      "        [13,  4,  9,  4, 13,  5],\n",
      "        [10,  4,  9,  4,  5,  5],\n",
      "        [10,  4,  9,  4,  5, 12],\n",
      "        [10,  4,  6,  4, 12, 13],\n",
      "        [ 7,  4,  6,  4, 12,  7],\n",
      "        [ 8,  4, 11,  4,  5, 12],\n",
      "        [13,  4, 12,  4,  6,  6],\n",
      "        [ 8,  4, 12,  4,  6,  9],\n",
      "        [ 7,  4,  8,  4, 13, 10],\n",
      "        [10,  4, 12,  4, 13,  8],\n",
      "        [11,  4, 11,  4, 14,  7],\n",
      "        [ 8,  4,  9,  4, 14,  9],\n",
      "        [12,  4,  8,  4, 12,  9],\n",
      "        [ 6,  4, 10,  4, 12, 13],\n",
      "        [ 6,  4, 10,  4, 12, 14],\n",
      "        [14,  4, 10,  4,  5, 12],\n",
      "        [10,  4, 12,  4,  6,  8],\n",
      "        [ 7,  4,  9,  4,  5, 12],\n",
      "        [ 6,  4, 12,  4,  5,  6],\n",
      "        [10,  4,  6,  4, 12,  5],\n",
      "        [ 9,  4, 13,  4,  5, 11],\n",
      "        [ 8,  4,  8,  4, 12,  5],\n",
      "        [10,  4,  8,  4, 14, 14],\n",
      "        [10,  4,  9,  4,  7,  6],\n",
      "        [ 7,  4,  8,  4, 13, 14],\n",
      "        [ 9,  4,  7,  4,  5,  9],\n",
      "        [12,  4,  6,  4,  7,  6],\n",
      "        [ 8,  4,  7,  4,  5, 13],\n",
      "        [12,  4,  8,  4, 12,  7],\n",
      "        [12,  4, 11,  4,  7,  7],\n",
      "        [ 8,  4,  9,  4,  6, 12],\n",
      "        [ 8,  4, 14,  4, 12, 11],\n",
      "        [ 8,  4,  7,  4,  6, 12],\n",
      "        [12,  4, 11,  4, 12, 14],\n",
      "        [ 8,  4,  9,  4, 14,  9],\n",
      "        [14,  4, 11,  4, 13, 10],\n",
      "        [13,  4, 10,  4, 13,  9],\n",
      "        [13,  4,  6,  4, 14, 10],\n",
      "        [13,  4, 13,  4, 13, 11],\n",
      "        [11,  4, 10,  4, 14, 13],\n",
      "        [10,  4,  6,  4,  6,  6],\n",
      "        [ 6,  4,  9,  4,  7,  6],\n",
      "        [ 6,  4, 10,  4, 12,  9],\n",
      "        [14,  4, 10,  4, 13, 14],\n",
      "        [12,  4, 12,  4, 12, 14],\n",
      "        [13,  4,  6,  4, 14, 13],\n",
      "        [ 9,  4,  6,  4,  6, 10],\n",
      "        [13,  4,  9,  4,  6, 11],\n",
      "        [14,  4, 11,  4, 13,  8],\n",
      "        [12,  4, 11,  4,  5,  9],\n",
      "        [ 9,  4, 10,  4, 12,  8],\n",
      "        [ 8,  4,  8,  4, 13,  7],\n",
      "        [10,  4, 11,  4,  5,  5],\n",
      "        [10,  4,  8,  4, 13,  5],\n",
      "        [11,  4,  7,  4,  6, 14],\n",
      "        [13,  4,  6,  4, 13,  5],\n",
      "        [11,  4,  8,  4, 13,  7],\n",
      "        [13,  4, 10,  4, 12, 11],\n",
      "        [14,  4, 12,  4,  6, 12],\n",
      "        [ 6,  4, 10,  4,  6,  6]])\n",
      "tensor([[ 1,  6,  4,  5,  4,  3,  4,  9,  3,  4, 12],\n",
      "        [ 1,  5, 13, 11,  6,  3,  4, 13,  3,  4,  7],\n",
      "        [ 1,  5, 13, 12,  4,  3,  4,  9,  3,  4,  8],\n",
      "        [ 1,  5, 13, 12,  9,  3,  4,  7,  3,  4, 11],\n",
      "        [ 1,  5, 13, 12,  4,  3,  4, 12,  3,  4,  8],\n",
      "        [ 1,  6,  4,  4,  4,  3,  4,  9,  3,  4,  8],\n",
      "        [ 1,  6,  4,  4, 11,  3,  4,  9,  3,  4,  8],\n",
      "        [ 1,  5, 13, 11, 12,  3,  4,  9,  3,  4,  5],\n",
      "        [ 1,  5, 13, 11,  6,  3,  4,  6,  3,  4,  5],\n",
      "        [ 1,  6,  4,  4, 11,  3,  4,  7,  3,  4, 10],\n",
      "        [ 1,  6,  4,  5,  5,  3,  4, 12,  3,  4, 11],\n",
      "        [ 1,  6,  4,  5,  8,  3,  4,  7,  3,  4, 11],\n",
      "        [ 1,  5, 13, 12,  9,  3,  4,  6,  3,  4,  7],\n",
      "        [ 1,  5, 13, 12,  7,  3,  4,  9,  3,  4, 11],\n",
      "        [ 1,  5, 13, 13,  6,  3,  4, 10,  3,  4, 10],\n",
      "        [ 1,  5, 13, 13,  8,  3,  4,  7,  3,  4,  8],\n",
      "        [ 1,  5, 13, 11,  8,  3,  4, 11,  3,  4,  7],\n",
      "        [ 1,  5, 13, 11, 12,  3,  4,  5,  3,  4,  9],\n",
      "        [ 1,  5, 13, 11, 13,  3,  4,  5,  3,  4,  9],\n",
      "        [ 1,  6,  4,  4, 11,  3,  4, 13,  3,  4,  9],\n",
      "        [ 1,  6,  4,  5,  7,  3,  4,  9,  3,  4, 11],\n",
      "        [ 1,  6,  4,  4, 11,  3,  4,  6,  3,  4,  8],\n",
      "        [ 1,  6,  4,  4,  5,  3,  4,  5,  3,  4, 11],\n",
      "        [ 1,  5, 13, 11,  4,  3,  4,  9,  3,  4,  5],\n",
      "        [ 1,  6,  4,  4, 10,  3,  4,  8,  3,  4, 12],\n",
      "        [ 1,  5, 13, 11,  4,  3,  4,  7,  3,  4,  7],\n",
      "        [ 1,  5, 13, 13, 13,  3,  4,  9,  3,  4,  7],\n",
      "        [ 1,  6,  4,  6,  5,  3,  4,  9,  3,  4,  8],\n",
      "        [ 1,  5, 13, 12, 13,  3,  4,  6,  3,  4,  7],\n",
      "        [ 1,  6,  4,  4,  8,  3,  4,  8,  3,  4,  6],\n",
      "        [ 1,  6,  4,  6,  5,  3,  4, 11,  3,  4,  5],\n",
      "        [ 1,  6,  4,  4, 12,  3,  4,  7,  3,  4,  6],\n",
      "        [ 1,  5, 13, 11,  6,  3,  4, 11,  3,  4,  7],\n",
      "        [ 1,  6,  4,  6,  6,  3,  4, 11,  3,  4, 10],\n",
      "        [ 1,  6,  4,  5, 11,  3,  4,  7,  3,  4,  8],\n",
      "        [ 1,  5, 13, 11, 10,  3,  4,  7,  3,  4, 13],\n",
      "        [ 1,  6,  4,  5, 11,  3,  4,  7,  3,  4,  6],\n",
      "        [ 1,  5, 13, 11, 13,  3,  4, 11,  3,  4, 10],\n",
      "        [ 1,  5, 13, 13,  8,  3,  4,  7,  3,  4,  8],\n",
      "        [ 1,  5, 13, 12,  9,  3,  4, 13,  3,  4, 10],\n",
      "        [ 1,  5, 13, 12,  8,  3,  4, 12,  3,  4,  9],\n",
      "        [ 1,  5, 13, 13,  9,  3,  4, 12,  3,  4,  5],\n",
      "        [ 1,  5, 13, 12, 10,  3,  4, 12,  3,  4, 12],\n",
      "        [ 1,  5, 13, 13, 12,  3,  4, 10,  3,  4,  9],\n",
      "        [ 1,  6,  4,  5,  5,  3,  4,  9,  3,  4,  5],\n",
      "        [ 1,  6,  4,  6,  5,  3,  4,  5,  3,  4,  8],\n",
      "        [ 1,  5, 13, 11,  8,  3,  4,  5,  3,  4,  9],\n",
      "        [ 1,  5, 13, 12, 13,  3,  4, 13,  3,  4,  9],\n",
      "        [ 1,  5, 13, 11, 13,  3,  4, 11,  3,  4, 11],\n",
      "        [ 1,  5, 13, 13, 12,  3,  4, 12,  3,  4,  5],\n",
      "        [ 1,  6,  4,  5,  9,  3,  4,  8,  3,  4,  5],\n",
      "        [ 1,  6,  4,  5, 10,  3,  4, 12,  3,  4,  8],\n",
      "        [ 1,  5, 13, 12,  7,  3,  4, 13,  3,  4, 10],\n",
      "        [ 1,  6,  4,  4,  8,  3,  4, 11,  3,  4, 10],\n",
      "        [ 1,  5, 13, 11,  7,  3,  4,  8,  3,  4,  9],\n",
      "        [ 1,  5, 13, 12,  6,  3,  4,  7,  3,  4,  7],\n",
      "        [ 1,  6,  4,  4,  4,  3,  4,  9,  3,  4, 10],\n",
      "        [ 1,  5, 13, 12,  4,  3,  4,  9,  3,  4,  7],\n",
      "        [ 1,  6,  4,  5, 13,  3,  4, 10,  3,  4,  6],\n",
      "        [ 1,  5, 13, 12,  4,  3,  4, 12,  3,  4,  5],\n",
      "        [ 1,  5, 13, 12,  6,  3,  4, 10,  3,  4,  7],\n",
      "        [ 1,  5, 13, 11, 10,  3,  4, 12,  3,  4,  9],\n",
      "        [ 1,  6,  4,  5, 11,  3,  4, 13,  3,  4, 11],\n",
      "        [ 1,  6,  4,  5,  5,  3,  4,  5,  3,  4,  9]])\n",
      "tensor([[ 6,  4,  5,  4,  3,  4,  9,  3,  4, 12,  2],\n",
      "        [ 5, 13, 11,  6,  3,  4, 13,  3,  4,  7,  2],\n",
      "        [ 5, 13, 12,  4,  3,  4,  9,  3,  4,  8,  2],\n",
      "        [ 5, 13, 12,  9,  3,  4,  7,  3,  4, 11,  2],\n",
      "        [ 5, 13, 12,  4,  3,  4, 12,  3,  4,  8,  2],\n",
      "        [ 6,  4,  4,  4,  3,  4,  9,  3,  4,  8,  2],\n",
      "        [ 6,  4,  4, 11,  3,  4,  9,  3,  4,  8,  2],\n",
      "        [ 5, 13, 11, 12,  3,  4,  9,  3,  4,  5,  2],\n",
      "        [ 5, 13, 11,  6,  3,  4,  6,  3,  4,  5,  2],\n",
      "        [ 6,  4,  4, 11,  3,  4,  7,  3,  4, 10,  2],\n",
      "        [ 6,  4,  5,  5,  3,  4, 12,  3,  4, 11,  2],\n",
      "        [ 6,  4,  5,  8,  3,  4,  7,  3,  4, 11,  2],\n",
      "        [ 5, 13, 12,  9,  3,  4,  6,  3,  4,  7,  2],\n",
      "        [ 5, 13, 12,  7,  3,  4,  9,  3,  4, 11,  2],\n",
      "        [ 5, 13, 13,  6,  3,  4, 10,  3,  4, 10,  2],\n",
      "        [ 5, 13, 13,  8,  3,  4,  7,  3,  4,  8,  2],\n",
      "        [ 5, 13, 11,  8,  3,  4, 11,  3,  4,  7,  2],\n",
      "        [ 5, 13, 11, 12,  3,  4,  5,  3,  4,  9,  2],\n",
      "        [ 5, 13, 11, 13,  3,  4,  5,  3,  4,  9,  2],\n",
      "        [ 6,  4,  4, 11,  3,  4, 13,  3,  4,  9,  2],\n",
      "        [ 6,  4,  5,  7,  3,  4,  9,  3,  4, 11,  2],\n",
      "        [ 6,  4,  4, 11,  3,  4,  6,  3,  4,  8,  2],\n",
      "        [ 6,  4,  4,  5,  3,  4,  5,  3,  4, 11,  2],\n",
      "        [ 5, 13, 11,  4,  3,  4,  9,  3,  4,  5,  2],\n",
      "        [ 6,  4,  4, 10,  3,  4,  8,  3,  4, 12,  2],\n",
      "        [ 5, 13, 11,  4,  3,  4,  7,  3,  4,  7,  2],\n",
      "        [ 5, 13, 13, 13,  3,  4,  9,  3,  4,  7,  2],\n",
      "        [ 6,  4,  6,  5,  3,  4,  9,  3,  4,  8,  2],\n",
      "        [ 5, 13, 12, 13,  3,  4,  6,  3,  4,  7,  2],\n",
      "        [ 6,  4,  4,  8,  3,  4,  8,  3,  4,  6,  2],\n",
      "        [ 6,  4,  6,  5,  3,  4, 11,  3,  4,  5,  2],\n",
      "        [ 6,  4,  4, 12,  3,  4,  7,  3,  4,  6,  2],\n",
      "        [ 5, 13, 11,  6,  3,  4, 11,  3,  4,  7,  2],\n",
      "        [ 6,  4,  6,  6,  3,  4, 11,  3,  4, 10,  2],\n",
      "        [ 6,  4,  5, 11,  3,  4,  7,  3,  4,  8,  2],\n",
      "        [ 5, 13, 11, 10,  3,  4,  7,  3,  4, 13,  2],\n",
      "        [ 6,  4,  5, 11,  3,  4,  7,  3,  4,  6,  2],\n",
      "        [ 5, 13, 11, 13,  3,  4, 11,  3,  4, 10,  2],\n",
      "        [ 5, 13, 13,  8,  3,  4,  7,  3,  4,  8,  2],\n",
      "        [ 5, 13, 12,  9,  3,  4, 13,  3,  4, 10,  2],\n",
      "        [ 5, 13, 12,  8,  3,  4, 12,  3,  4,  9,  2],\n",
      "        [ 5, 13, 13,  9,  3,  4, 12,  3,  4,  5,  2],\n",
      "        [ 5, 13, 12, 10,  3,  4, 12,  3,  4, 12,  2],\n",
      "        [ 5, 13, 13, 12,  3,  4, 10,  3,  4,  9,  2],\n",
      "        [ 6,  4,  5,  5,  3,  4,  9,  3,  4,  5,  2],\n",
      "        [ 6,  4,  6,  5,  3,  4,  5,  3,  4,  8,  2],\n",
      "        [ 5, 13, 11,  8,  3,  4,  5,  3,  4,  9,  2],\n",
      "        [ 5, 13, 12, 13,  3,  4, 13,  3,  4,  9,  2],\n",
      "        [ 5, 13, 11, 13,  3,  4, 11,  3,  4, 11,  2],\n",
      "        [ 5, 13, 13, 12,  3,  4, 12,  3,  4,  5,  2],\n",
      "        [ 6,  4,  5,  9,  3,  4,  8,  3,  4,  5,  2],\n",
      "        [ 6,  4,  5, 10,  3,  4, 12,  3,  4,  8,  2],\n",
      "        [ 5, 13, 12,  7,  3,  4, 13,  3,  4, 10,  2],\n",
      "        [ 6,  4,  4,  8,  3,  4, 11,  3,  4, 10,  2],\n",
      "        [ 5, 13, 11,  7,  3,  4,  8,  3,  4,  9,  2],\n",
      "        [ 5, 13, 12,  6,  3,  4,  7,  3,  4,  7,  2],\n",
      "        [ 6,  4,  4,  4,  3,  4,  9,  3,  4, 10,  2],\n",
      "        [ 5, 13, 12,  4,  3,  4,  9,  3,  4,  7,  2],\n",
      "        [ 6,  4,  5, 13,  3,  4, 10,  3,  4,  6,  2],\n",
      "        [ 5, 13, 12,  4,  3,  4, 12,  3,  4,  5,  2],\n",
      "        [ 5, 13, 12,  6,  3,  4, 10,  3,  4,  7,  2],\n",
      "        [ 5, 13, 11, 10,  3,  4, 12,  3,  4,  9,  2],\n",
      "        [ 6,  4,  5, 11,  3,  4, 13,  3,  4, 11,  2],\n",
      "        [ 6,  4,  5,  5,  3,  4,  5,  3,  4,  9,  2]])\n",
      "EncoderGRU(\n",
      "  (gru): GRU(37, 32, batch_first=True)\n",
      ")\n",
      "torch.Size([64, 6, 32]) torch.Size([1, 64, 32])\n"
     ]
    }
   ],
   "source": [
    "x_enc_batch,  x_dec_batch, y_batch = next(iter(train_loader))\n",
    "print(x_enc_batch)\n",
    "print(x_dec_batch)\n",
    "print(y_batch)\n",
    "encoder = EncoderGRU(len(human_vocab), hidden_size=32, num_layers=1, bidirectional=False)\n",
    "print(encoder)\n",
    "enc_out, enc_hidden = encoder(x_enc_batch)\n",
    "print(enc_out.shape, enc_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/8/10\n",
      "9/3/72\n",
      "5/4/80\n",
      "3/7/85\n",
      "8/4/80\n",
      "5/4/00\n",
      "5/4/07\n",
      "5/1/78\n",
      "2/1/72\n",
      "3/6/07\n",
      "8/7/11\n",
      "3/7/14\n",
      "2/3/85\n",
      "5/7/83\n",
      "6/6/92\n",
      "3/4/94\n",
      "7/3/74\n",
      "1/5/78\n",
      "1/5/79\n",
      "9/5/07\n",
      "5/7/13\n",
      "2/4/07\n",
      "1/7/01\n",
      "5/1/70\n",
      "4/8/06\n",
      "3/3/70\n",
      "5/3/99\n",
      "5/4/21\n",
      "2/3/89\n",
      "4/2/04\n",
      "7/1/21\n",
      "3/2/08\n",
      "7/3/72\n",
      "7/6/22\n",
      "3/4/17\n",
      "3/9/76\n",
      "3/2/17\n",
      "7/6/79\n",
      "3/4/94\n",
      "9/6/85\n",
      "8/5/84\n",
      "8/1/95\n",
      "8/8/86\n",
      "6/5/98\n",
      "5/1/11\n",
      "1/4/21\n",
      "1/5/74\n",
      "9/5/89\n",
      "7/7/79\n",
      "8/1/98\n",
      "4/1/15\n",
      "8/4/16\n",
      "9/6/83\n",
      "7/6/04\n",
      "4/5/73\n",
      "3/3/82\n",
      "5/6/00\n",
      "5/3/80\n",
      "6/2/19\n",
      "8/1/80\n",
      "6/3/82\n",
      "8/5/76\n",
      "9/7/17\n",
      "1/5/11\n"
     ]
    }
   ],
   "source": [
    "lang = train_dataset.input_lang\n",
    "for row in x_enc_batch:\n",
    "    print(lang.ind_to_str(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers=1):\n",
    "        super(DecoderGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(\n",
    "            vocab_size, hidden_size, num_layers=num_layers, batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        if hidden == None:\n",
    "            hidden = self.init_hidden(x.shape[0]).to(x.device)\n",
    "        one_hot = F.one_hot(x, num_classes=self.vocab_size).float().to(x.device)\n",
    "        output, hidden = self.gru(one_hot, hidden)\n",
    "        output = self.fc(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(\n",
    "            self.gru.num_layers, batch_size, self.hidden_size, dtype=torch.float32\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecoderGRU(\n",
      "  (gru): GRU(14, 32, batch_first=True)\n",
      "  (fc): Linear(in_features=32, out_features=14, bias=True)\n",
      ")\n",
      "EncoderGRU(\n",
      "  (gru): GRU(37, 32, batch_first=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderGRU(len(human_vocab), hidden_size=32, num_layers=1, bidirectional=False)\n",
    "decoder = DecoderGRU(len(machine_vocab), hidden_size=32, num_layers=1)\n",
    "print(decoder)\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder forward pass\n",
      "\n",
      "Training with teacher forcing\n",
      "Input batch shape: torch.Size([64, 11])\n",
      "decoder output shape: torch.Size([64, 11, 14])\n",
      "decoder hn shape: torch.Size([1, 64, 32])\n",
      "\n",
      "Training without teacher forcing\n",
      "Decoder 1st input shape: torch.Size([64, 1])\n",
      "decoder output shape: torch.Size([64, 1, 14])\n",
      "decoder hn shape: torch.Size([1, 64, 32])\n",
      "decoder 2nd input shape: torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"Decoder forward pass\\n\")\n",
    "\n",
    "# Teacher forcing\n",
    "print(\"Training with teacher forcing\")\n",
    "print(f\"Input batch shape: {x_dec_batch.shape}\")\n",
    "dec_out, dec_hid = decoder(x_dec_batch, enc_hidden)\n",
    "print(f\"decoder output shape: {dec_out.shape}\\ndecoder hn shape: {dec_hid.shape}\")\n",
    "# loss(dec_out, target)\n",
    "print()\n",
    "# Without teacher forcing\n",
    "print(\"Training without teacher forcing\")\n",
    "dec_input = x_dec_batch[:,0:1]\n",
    "print(f\"Decoder 1st input shape: {dec_input.shape}\")\n",
    "dec_out, dec_hid = decoder(dec_input, enc_hidden)\n",
    "print(f\"decoder output shape: {dec_out.shape}\\ndecoder hn shape: {dec_hid.shape}\")\n",
    "next_input = torch.argmax(dec_out, dim=-1)\n",
    "print(f\"decoder 2nd input shape: {next_input.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2sec(nn.Module):\n",
    "    def __init__(self, encoder, decoder) -> None:\n",
    "        super(Seq2sec, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_input_batch, sos_index = 1, dec_input_batch = None, teacher_forcing = False, out_length = 1):\n",
    "        encoder_output, encoder_hidden = self.encoder(enc_input_batch)\n",
    "        batch_size = len(enc_input_batch)\n",
    "\n",
    "        if teacher_forcing:\n",
    "            decoder_output, _ = self.decoder(dec_input_batch, encoder_hidden)\n",
    "            return decoder_output\n",
    "        else:\n",
    "            decoder_input = (torch.zeros(batch_size, 1, dtype=torch.int64) + sos_index).to(enc_input_batch.device)\n",
    "            decoder_output = torch.empty(batch_size, out_length, self.decoder.vocab_size).to(enc_input_batch.device)\n",
    "\n",
    "            hidden = encoder_hidden\n",
    "\n",
    "            for i in range(out_length):\n",
    "                decoder_output_i, hidden = self.decoder(decoder_input, hidden)\n",
    "                decoder_output[:,i:i+1,:] = decoder_output_i\n",
    "                decoder_input = torch.argmax(decoder_output_i, dim=-1)\n",
    "\n",
    "            return decoder_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2sec(\n",
       "  (encoder): EncoderGRU(\n",
       "    (gru): GRU(37, 32, batch_first=True)\n",
       "  )\n",
       "  (decoder): DecoderGRU(\n",
       "    (gru): GRU(14, 32, batch_first=True)\n",
       "    (fc): Linear(in_features=32, out_features=14, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Seq2sec(encoder, decoder)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20, 14])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_enc_batch, out_length = 20).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 11, 14])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_enc_batch, dec_input_batch = x_dec_batch, teacher_forcing = True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model forward pass (input -> encoder -> decoder -> output)\n",
      "\n",
      "Training without teacher forcing (out_length = 20)\n",
      "Input batch shape: torch.Size([64, 6])\n",
      "Output shape: torch.Size([64, 20, 14])\n",
      "\n",
      "Training with teacher forcing\n",
      "Encoder input batch shape: torch.Size([64, 6])\n",
      "Decoder input batch shape: torch.Size([64, 11])\n",
      "Output shape: torch.Size([64, 11, 14])\n"
     ]
    }
   ],
   "source": [
    "print(\"Model forward pass (input -> encoder -> decoder -> output)\\n\")\n",
    "\n",
    "# Teacher forcing\n",
    "print(\"Training without teacher forcing (out_length = 20)\")\n",
    "print(f\"Input batch shape: {x_enc_batch.shape}\")\n",
    "output =  model(x_enc_batch, out_length = 20)\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "\n",
    "print()\n",
    "# Without teacher forcing\n",
    "print(\"Training with teacher forcing\")\n",
    "print(f\"Encoder input batch shape: {x_enc_batch.shape}\")\n",
    "print(f\"Decoder input batch shape: {x_dec_batch.shape}\")\n",
    "output = model(x_enc_batch, dec_input_batch = x_dec_batch, teacher_forcing = True)\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_dataLoader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        val_dataLoader=None,\n",
    "        padding_index=0,\n",
    "        sos_index=1,\n",
    "        teacher_forcing_ratio=0.5,\n",
    "        device=device,\n",
    "    ) -> None:\n",
    "        self.model = model.to(device)\n",
    "        self.train_dataLoader = train_dataLoader\n",
    "        self.val_dataLoader = val_dataLoader\n",
    "        self.loss_fn = loss_fn\n",
    "        self.padding_index = padding_index\n",
    "        self.sos_index = sos_index\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def loss_value(self, output, target):\n",
    "        C = output.shape[-1]\n",
    "\n",
    "        output_flat = output.view(-1, C)\n",
    "        target_flat = target.view(-1)\n",
    "\n",
    "        loss = self.loss_fn(output_flat, target_flat)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def train_batch(self, encoder_input, decoder_input, target):\n",
    "        teacher_forcing = np.random.random() < self.teacher_forcing_ratio\n",
    "\n",
    "        output = self.model(\n",
    "            encoder_input,\n",
    "            dec_input_batch=decoder_input,\n",
    "            teacher_forcing=teacher_forcing,\n",
    "            sos_index=self.sos_index,\n",
    "            out_length=target.shape[1],\n",
    "        )\n",
    "\n",
    "        loss = self.loss_value(output, target)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    def train_one_epoch(self):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        epoch_loss = 0\n",
    "        batch_losses = []\n",
    "\n",
    "        i = 1\n",
    "\n",
    "        for enc_input, dec_input, target in self.train_dataLoader:\n",
    "            i += 1\n",
    "            enc_input = enc_input.to(self.device)\n",
    "            dec_input = dec_input.to(self.device)\n",
    "            target = target.to(self.device)\n",
    "\n",
    "            batch_loss = self.train_batch(\n",
    "                encoder_input=enc_input, decoder_input=dec_input, target=target\n",
    "            )\n",
    "\n",
    "            epoch_loss += batch_loss * len(enc_input)\n",
    "            batch_losses.append(batch_loss)\n",
    "\n",
    "        size = len(self.train_dataLoader.dataset)\n",
    "\n",
    "        return epoch_loss / size, batch_losses\n",
    "\n",
    "    def validation(self):\n",
    "        size = len(self.val_dataLoader.dataset)\n",
    "        model.eval()\n",
    "\n",
    "        test_loss = 0\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            for enc_input, _, target in self.val_dataLoader:\n",
    "                enc_input = enc_input.to(self.device)\n",
    "                target = target.to(self.device)\n",
    "\n",
    "                out = self.model(\n",
    "                    enc_input,\n",
    "                    teacher_forcing=False,\n",
    "                    sos_index=self.sos_index,\n",
    "                    out_length=target.shape[1],\n",
    "                )\n",
    "                test_loss += self.loss_value(out, target).item() * len(enc_input)\n",
    "\n",
    "            return test_loss / size\n",
    "\n",
    "    def train(self, n_epochs, verbose = True):\n",
    "        for epoch in range(n_epochs):\n",
    "            epoch_loss, batch_losses = self.train_one_epoch()\n",
    "\n",
    "            if self.val_dataLoader != None:\n",
    "                val_loss = self.validation()\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"Epoch {epoch + 1 :< 4}  training loss: {epoch_loss:>8f} | validation loss: {val_loss:>8f}\")\\\n",
    "                    \n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"Epoch {epoch + 1 :< 10}  training loss: {epoch_loss:>8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "cross_entropy_loss = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "trainer = Trainer(model, train_dataLoader=train_loader, val_dataLoader=val_loader, loss_fn= cross_entropy_loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1    training loss: 0.678488 | validation loss: 0.745853\n",
      "Epoch  2    training loss: 0.667945 | validation loss: 0.731366\n",
      "Epoch  3    training loss: 0.657139 | validation loss: 0.720331\n",
      "Epoch  4    training loss: 0.649183 | validation loss: 0.715878\n",
      "Epoch  5    training loss: 0.633723 | validation loss: 0.696993\n",
      "Epoch  6    training loss: 0.634708 | validation loss: 0.689045\n",
      "Epoch  7    training loss: 0.623650 | validation loss: 0.684317\n",
      "Epoch  8    training loss: 0.619833 | validation loss: 0.673395\n",
      "Epoch  9    training loss: 0.615610 | validation loss: 0.664424\n",
      "Epoch  10   training loss: 0.607913 | validation loss: 0.662807\n",
      "Epoch  11   training loss: 0.608215 | validation loss: 0.656183\n",
      "Epoch  12   training loss: 0.600462 | validation loss: 0.667898\n",
      "Epoch  13   training loss: 0.610181 | validation loss: 0.654832\n",
      "Epoch  14   training loss: 0.599423 | validation loss: 0.646188\n",
      "Epoch  15   training loss: 0.598755 | validation loss: 0.646291\n",
      "Epoch  16   training loss: 0.597133 | validation loss: 0.646344\n",
      "Epoch  17   training loss: 0.597167 | validation loss: 0.647285\n",
      "Epoch  18   training loss: 0.591095 | validation loss: 0.652761\n",
      "Epoch  19   training loss: 0.587080 | validation loss: 0.640314\n",
      "Epoch  20   training loss: 0.594034 | validation loss: 0.663775\n",
      "Epoch  21   training loss: 0.595191 | validation loss: 0.652310\n",
      "Epoch  22   training loss: 0.588866 | validation loss: 0.642721\n",
      "Epoch  23   training loss: 0.581503 | validation loss: 0.638597\n",
      "Epoch  24   training loss: 0.581925 | validation loss: 0.634532\n",
      "Epoch  25   training loss: 0.580226 | validation loss: 0.634804\n",
      "Epoch  26   training loss: 0.567532 | validation loss: 0.603386\n",
      "Epoch  27   training loss: 0.551699 | validation loss: 0.602591\n",
      "Epoch  28   training loss: 0.543045 | validation loss: 0.597300\n",
      "Epoch  29   training loss: 0.537470 | validation loss: 0.576423\n",
      "Epoch  30   training loss: 0.521139 | validation loss: 0.561732\n",
      "Epoch  31   training loss: 0.511473 | validation loss: 0.560896\n",
      "Epoch  32   training loss: 0.502690 | validation loss: 0.551885\n",
      "Epoch  33   training loss: 0.496999 | validation loss: 0.538338\n",
      "Epoch  34   training loss: 0.488806 | validation loss: 0.548812\n",
      "Epoch  35   training loss: 0.483470 | validation loss: 0.544441\n",
      "Epoch  36   training loss: 0.480660 | validation loss: 0.534467\n",
      "Epoch  37   training loss: 0.473871 | validation loss: 0.532675\n",
      "Epoch  38   training loss: 0.468585 | validation loss: 0.523847\n",
      "Epoch  39   training loss: 0.463387 | validation loss: 0.517837\n",
      "Epoch  40   training loss: 0.457117 | validation loss: 0.508635\n"
     ]
    }
   ],
   "source": [
    "trainer.train(40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
