{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils import load_dataset\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 34426.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0', '2', '6', '4', '-', '1', '9', '3', '5', '7', '8'} 11\n",
      "{'>': 0, '<': 1, '-': 2, '0': 3, '1': 4, '2': 5, '3': 6, '4': 7, '5': 8, '6': 9, '7': 10, '8': 11, '9': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "m = 10000\n",
    "data, human_vocab, machine_vocab = load_dataset(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{';': 0,\n",
       " '?': 1,\n",
       " ' ': 2,\n",
       " '.': 3,\n",
       " '/': 4,\n",
       " '0': 5,\n",
       " '1': 6,\n",
       " '2': 7,\n",
       " '3': 8,\n",
       " '4': 9,\n",
       " '5': 10,\n",
       " '6': 11,\n",
       " '7': 12,\n",
       " '8': 13,\n",
       " '9': 14,\n",
       " 'a': 15,\n",
       " 'b': 16,\n",
       " 'c': 17,\n",
       " 'd': 18,\n",
       " 'e': 19,\n",
       " 'f': 20,\n",
       " 'g': 21,\n",
       " 'h': 22,\n",
       " 'i': 23,\n",
       " 'j': 24,\n",
       " 'l': 25,\n",
       " 'm': 26,\n",
       " 'n': 27,\n",
       " 'o': 28,\n",
       " 'p': 29,\n",
       " 'r': 30,\n",
       " 's': 31,\n",
       " 't': 32,\n",
       " 'u': 33,\n",
       " 'v': 34,\n",
       " 'w': 35,\n",
       " 'y': 36}"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'>': 0,\n",
       " '<': 1,\n",
       " '-': 2,\n",
       " '0': 3,\n",
       " '1': 4,\n",
       " '2': 5,\n",
       " '3': 6,\n",
       " '4': 7,\n",
       " '5': 8,\n",
       " '6': 9,\n",
       " '7': 10,\n",
       " '8': 11,\n",
       " '9': 12}"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('8/8/71', '>1971-08-08<'),\n",
       " ('3/3/81', '>1981-03-03<'),\n",
       " ('4/8/96', '>1996-04-08<'),\n",
       " ('4/9/78', '>1978-04-09<'),\n",
       " ('6/5/73', '>1973-06-05<'),\n",
       " ('5/2/89', '>1989-05-02<'),\n",
       " ('2/1/98', '>1998-02-01<'),\n",
       " ('8/5/79', '>1979-08-05<'),\n",
       " ('6/7/18', '>2018-06-07<'),\n",
       " ('6/8/89', '>1989-06-08<'),\n",
       " ('6/3/18', '>2018-06-03<'),\n",
       " ('2/7/21', '>2021-02-07<'),\n",
       " ('5/5/20', '>2020-05-05<'),\n",
       " ('8/6/88', '>1988-08-06<'),\n",
       " ('3/5/06', '>2006-03-05<'),\n",
       " ('9/2/71', '>1971-09-02<'),\n",
       " ('5/8/92', '>1992-05-08<'),\n",
       " ('1/9/99', '>1999-01-09<'),\n",
       " ('2/1/92', '>1992-02-01<'),\n",
       " ('9/4/83', '>1983-09-04<')]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, vocab: dict):\n",
    "        self.vocab = vocab\n",
    "        self.inv_vocab = {v:k for k,v in vocab.items()}\n",
    "        self.vocab_size = len(vocab)\n",
    "\n",
    "    def str_to_ind(self, str):\n",
    "        return [self.vocab[c] for c in str]\n",
    "    \n",
    "    def ind_to_str(self, ind):\n",
    "        return ''.join([self.inv_vocab[i] for i in ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8/71\n",
      "[13, 4, 13, 4, 12, 6]\n",
      "8/8/71\n"
     ]
    }
   ],
   "source": [
    "test = Lang(human_vocab)\n",
    "date = data[0][0]\n",
    "print(date)\n",
    "translated_date = test.str_to_ind(date)\n",
    "print(translated_date)\n",
    "reversed_translation = test.ind_to_str(translated_date)\n",
    "print(reversed_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, data, input_vocab, output_vocab):\n",
    "        self.input_lang = Lang(input_vocab)\n",
    "        self.target_lang = Lang(output_vocab)\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "        self.inputs = [self.input_lang.str_to_ind(input_sent) for input_sent, _ in self.data]\n",
    "        self.targets = [self.target_lang.str_to_ind(target_sent) for _, target_sent in self.data]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.inputs[index], self.targets[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TranslationDataset(data, human_vocab, machine_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 4, 13, 4, 12, 6] 8/8/71\n",
      "[0, 4, 12, 10, 4, 2, 3, 11, 2, 3, 11, 1] >1971-08-08<\n"
     ]
    }
   ],
   "source": [
    "x,y = dataset[0]\n",
    "print(x, dataset.input_lang.ind_to_str(x))\n",
    "print(y, dataset.target_lang.ind_to_str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(data):\n",
    "    inputs = [torch.tensor(item[0], dtype=torch.int64) for item in data]\n",
    "    targets = [torch.tensor(item[1], dtype=torch.int64) for item in data]\n",
    "\n",
    "    input_batch = nn.utils.rnn.pad_sequence(inputs, batch_first=True)\n",
    "    target_batch = torch.stack(targets)\n",
    "\n",
    "    return input_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=dataset, collate_fn=collate_batch, batch_size = 2, num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers = 1):\n",
    "        super(EncoderGRU, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(vocab_size, hidden_size, num_layers = num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, input, hidden = None):\n",
    "        if hidden == None:\n",
    "            hidden = self.init_hidden(input.shape[0]).to(input.device)\n",
    "        one_hot = F.one_hot(input, num_classes=self.vocab_size).float()\n",
    "        output, hidden = self.gru(one_hot, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.gru.num_layers, batch_size, self.hidden_size, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[13,  4, 13,  4, 12,  6],\n",
      "        [ 8,  4,  8,  4, 13,  6]])\n",
      "tensor([[ 0,  4, 12, 10,  4,  2,  3, 11,  2,  3, 11,  1],\n",
      "        [ 0,  4, 12, 11,  4,  2,  3,  6,  2,  3,  6,  1]])\n"
     ]
    }
   ],
   "source": [
    "x_batch, y_batch = next(iter(loader))\n",
    "print(x_batch)\n",
    "print(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderGRU(\n",
       "  (gru): GRU(37, 10, batch_first=True)\n",
       ")"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = EncoderGRU(len(human_vocab), 10, num_layers=1)\n",
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 10]) torch.Size([1, 2, 10])\n"
     ]
    }
   ],
   "source": [
    "out, hn = encoder(x_batch)\n",
    "print(out.shape, hn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "print(encoder.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 37])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(x_batch, num_classes=37).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers = 1):\n",
    "        super(DecoderGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(vocab_size, hidden_size, num_layers = num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        # self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        if hidden == None:\n",
    "            hidden = self.init_hidden(x.shape[0]).to(x.device)\n",
    "        one_hot = F.one_hot(input, num_classes=self.vocab_size).float()\n",
    "        print(one_hot.shape)\n",
    "        output, hidden = self.gru(one_hot, hidden)\n",
    "        output = self.fc(output)\n",
    "        # output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.gru.num_layers, batch_size, self.hidden_size, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderGRU(\n",
       "  (gru): GRU(13, 10, batch_first=True)\n",
       "  (fc): Linear(in_features=10, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = DecoderGRU(len(machine_vocab), 10, num_layers=1)\n",
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 12])\n"
     ]
    }
   ],
   "source": [
    "print(y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 12, 13])\n",
      "torch.Size([2, 12, 13]) torch.Size([1, 2, 10])\n"
     ]
    }
   ],
   "source": [
    "y, h = decoder(y_batch, hn)\n",
    "print(y.shape, h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.vocab_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
