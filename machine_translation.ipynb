{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils import load_dataset, SpecialTokens\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 31052.43it/s]\n"
     ]
    }
   ],
   "source": [
    "m = 10000\n",
    "data, human_vocab, machine_vocab = load_dataset(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{';': 0,\n",
       " '?': 1,\n",
       " ' ': 2,\n",
       " '.': 3,\n",
       " '/': 4,\n",
       " '0': 5,\n",
       " '1': 6,\n",
       " '2': 7,\n",
       " '3': 8,\n",
       " '4': 9,\n",
       " '5': 10,\n",
       " '6': 11,\n",
       " '7': 12,\n",
       " '8': 13,\n",
       " '9': 14,\n",
       " 'a': 15,\n",
       " 'b': 16,\n",
       " 'c': 17,\n",
       " 'd': 18,\n",
       " 'e': 19,\n",
       " 'f': 20,\n",
       " 'g': 21,\n",
       " 'h': 22,\n",
       " 'i': 23,\n",
       " 'j': 24,\n",
       " 'l': 25,\n",
       " 'm': 26,\n",
       " 'n': 27,\n",
       " 'o': 28,\n",
       " 'p': 29,\n",
       " 'r': 30,\n",
       " 's': 31,\n",
       " 't': 32,\n",
       " 'u': 33,\n",
       " 'v': 34,\n",
       " 'w': 35,\n",
       " 'y': 36}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{';': 0,\n",
       " '>': 1,\n",
       " '<': 2,\n",
       " '-': 3,\n",
       " '0': 4,\n",
       " '1': 5,\n",
       " '2': 6,\n",
       " '3': 7,\n",
       " '4': 8,\n",
       " '5': 9,\n",
       " '6': 10,\n",
       " '7': 11,\n",
       " '8': 12,\n",
       " '9': 13}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('8/8/71', '>1971-08-08<'),\n",
       " ('3/3/81', '>1981-03-03<'),\n",
       " ('4/8/96', '>1996-04-08<'),\n",
       " ('4/9/78', '>1978-04-09<'),\n",
       " ('6/5/73', '>1973-06-05<'),\n",
       " ('5/2/89', '>1989-05-02<'),\n",
       " ('2/1/98', '>1998-02-01<'),\n",
       " ('8/5/79', '>1979-08-05<'),\n",
       " ('6/7/18', '>2018-06-07<'),\n",
       " ('6/8/89', '>1989-06-08<'),\n",
       " ('6/3/18', '>2018-06-03<'),\n",
       " ('2/7/21', '>2021-02-07<'),\n",
       " ('5/5/20', '>2020-05-05<'),\n",
       " ('8/6/88', '>1988-08-06<'),\n",
       " ('1/2/17', '>2017-01-02<'),\n",
       " ('7/6/99', '>1999-07-06<'),\n",
       " ('9/7/00', '>2000-09-07<'),\n",
       " ('3/8/78', '>1978-03-08<'),\n",
       " ('5/8/96', '>1996-05-08<'),\n",
       " ('5/3/19', '>2019-05-03<')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def _get_char(self, ind):\n",
    "        if isinstance(ind, torch.Tensor):\n",
    "            return self.inv_vocab[ind.item()]\n",
    "        else:\n",
    "            return self.inv_vocab[ind]\n",
    "\n",
    "    def __init__(self, vocab: dict):\n",
    "        self.vocab = vocab\n",
    "        self.inv_vocab = {v:k for k,v in vocab.items()}\n",
    "        self.vocab_size = len(vocab)\n",
    "\n",
    "    def str_to_ind(self, str):\n",
    "        return [self.vocab[c] for c in str]\n",
    "    \n",
    "    def ind_to_str(self, ind):\n",
    "        return ''.join([self._get_char(i) for i in ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8/71\n",
      "[13, 4, 13, 4, 12, 6]\n",
      "8/8/71\n"
     ]
    }
   ],
   "source": [
    "test = Lang(human_vocab)\n",
    "date = data[0][0]\n",
    "print(date)\n",
    "translated_date = test.str_to_ind(date)\n",
    "print(translated_date)\n",
    "reversed_translation = test.ind_to_str(translated_date)\n",
    "print(reversed_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationTrainingDataset(Dataset):\n",
    "    def __init__(self, data, input_vocab, output_vocab):\n",
    "        self.input_lang = Lang(input_vocab)\n",
    "        self.target_lang = Lang(output_vocab)\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "        self.encoder_inputs = [self.input_lang.str_to_ind(input_sent) for input_sent, _ in self.data]\n",
    "\n",
    "        targets = [self.target_lang.str_to_ind(target_sent) for _, target_sent in self.data]\n",
    "        self.decoder_inputs = [target[:-1] for target in targets]\n",
    "        self.decoder_targets = [target[1:] for target in targets]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoder_inputs[index], self.decoder_inputs[index], self.decoder_targets[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encoder_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TranslationTrainingDataset(data, human_vocab, machine_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 4, 13, 4, 12, 6] 8/8/71\n",
      "[1, 5, 13, 11, 5, 3, 4, 12, 3, 4, 12] >1971-08-08\n",
      "[5, 13, 11, 5, 3, 4, 12, 3, 4, 12, 2] 1971-08-08<\n"
     ]
    }
   ],
   "source": [
    "x,y,z = dataset[0]\n",
    "print(x, dataset.input_lang.ind_to_str(x))\n",
    "print(y, dataset.target_lang.ind_to_str(y))\n",
    "print(z, dataset.target_lang.ind_to_str(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(data):\n",
    "    batch = []\n",
    "    for i in range(len(data[0])):\n",
    "        batch_data = [torch.tensor(item[i], dtype=torch.int64) for item in data]\n",
    "        batch_data = nn.utils.rnn.pad_sequence(batch_data, batch_first=True)\n",
    "        batch.append(batch_data)\n",
    "\n",
    "\n",
    "    return tuple(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=dataset, collate_fn=collate_batch, batch_size = 2, num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers=1, bidirectional=False):\n",
    "        super(EncoderGRU, self).__init__()\n",
    "        self.D = 2 if bidirectional else 1\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(\n",
    "            vocab_size,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        if hidden == None:\n",
    "            hidden = self.init_hidden(x.shape[0]).to(x.device)\n",
    "\n",
    "        one_hot = F.one_hot(x, num_classes=self.vocab_size).float()\n",
    "\n",
    "        output, hidden = self.gru(one_hot, hidden)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(\n",
    "            self.D * self.gru.num_layers,\n",
    "            batch_size,\n",
    "            self.hidden_size,\n",
    "            dtype=torch.float32,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[13,  4, 13,  4, 12,  6],\n",
      "        [ 8,  4,  8,  4, 13,  6]])\n",
      "tensor([[ 1,  5, 13, 11,  5,  3,  4, 12,  3,  4, 12],\n",
      "        [ 1,  5, 13, 12,  5,  3,  4,  7,  3,  4,  7]])\n",
      "tensor([[ 5, 13, 11,  5,  3,  4, 12,  3,  4, 12,  2],\n",
      "        [ 5, 13, 12,  5,  3,  4,  7,  3,  4,  7,  2]])\n",
      "EncoderGRU(\n",
      "  (gru): GRU(37, 32, batch_first=True)\n",
      ")\n",
      "torch.Size([2, 6, 32]) torch.Size([1, 2, 32])\n"
     ]
    }
   ],
   "source": [
    "x_enc_batch,  x_dec_batch, y_batch = next(iter(loader))\n",
    "print(x_enc_batch)\n",
    "print(x_dec_batch)\n",
    "print(y_batch)\n",
    "encoder = EncoderGRU(len(human_vocab), hidden_size=32, num_layers=1, bidirectional=False)\n",
    "print(encoder)\n",
    "enc_out, enc_hidden = encoder(x_enc_batch)\n",
    "print(enc_out.shape, enc_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers=1):\n",
    "        super(DecoderGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(\n",
    "            vocab_size, hidden_size, num_layers=num_layers, batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        if hidden == None:\n",
    "            hidden = self.init_hidden(x.shape[0]).to(x.device)\n",
    "        one_hot = F.one_hot(x, num_classes=self.vocab_size).float()\n",
    "        output, hidden = self.gru(one_hot, hidden)\n",
    "        output = self.fc(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(\n",
    "            self.gru.num_layers, batch_size, self.hidden_size, dtype=torch.float32\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderGRU(\n",
       "  (gru): GRU(14, 32, batch_first=True)\n",
       "  (fc): Linear(in_features=32, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = DecoderGRU(len(machine_vocab), hidden_size=32, num_layers=1)\n",
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder forward pass\n",
      "\n",
      "Training with teacher forcing\n",
      "Input batch shape: torch.Size([2, 11])\n",
      "decoder output shape: torch.Size([2, 11, 14])\n",
      "decoder hn shape: torch.Size([1, 2, 32])\n",
      "\n",
      "Training without teacher forcing\n",
      "Decoder 1st input shape: torch.Size([2, 1])\n",
      "decoder output shape: torch.Size([2, 1, 14])\n",
      "decoder hn shape: torch.Size([1, 2, 32])\n",
      "decoder 2nd input shape: torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"Decoder forward pass\\n\")\n",
    "\n",
    "# Teacher forcing\n",
    "print(\"Training with teacher forcing\")\n",
    "print(f\"Input batch shape: {x_dec_batch.shape}\")\n",
    "dec_out, dec_hid = decoder(x_dec_batch, enc_hidden)\n",
    "print(f\"decoder output shape: {dec_out.shape}\\ndecoder hn shape: {dec_hid.shape}\")\n",
    "# loss(dec_out, target)\n",
    "print()\n",
    "# Without teacher forcing\n",
    "print(\"Training without teacher forcing\")\n",
    "dec_input = x_dec_batch[:,0:1]\n",
    "print(f\"Decoder 1st input shape: {dec_input.shape}\")\n",
    "dec_out, dec_hid = decoder(dec_input, enc_hidden)\n",
    "print(f\"decoder output shape: {dec_out.shape}\\ndecoder hn shape: {dec_hid.shape}\")\n",
    "next_input = torch.argmax(dec_out, dim=-1)\n",
    "print(f\"decoder 2nd input shape: {next_input.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2sec(nn.Module):\n",
    "    def __init__(self, encoder, decoder) -> None:\n",
    "        super(Seq2sec, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_input_batch, sos_index = 1, dec_input_batch = None, teacher_forcing = False, out_length = 100):\n",
    "        encoder_output, encoder_hidden = self.encoder(enc_input_batch)\n",
    "        batch_size = len(enc_input_batch)\n",
    "\n",
    "        if teacher_forcing:\n",
    "            decoder_output, _ = self.decoder(dec_input_batch, encoder_hidden)\n",
    "            return decoder_output\n",
    "        else:\n",
    "            decoder_input = torch.zeros(batch_size, 1, dtype=torch.int64) + sos_index\n",
    "            decoder_output = torch.empty(batch_size, out_length, self.decoder.vocab_size)\n",
    "\n",
    "            hidden = encoder_hidden\n",
    "\n",
    "            for i in range(out_length):\n",
    "                decoder_output_i, hidden = self.decoder(decoder_input, hidden)\n",
    "                decoder_output[:,i:i+1,:] = decoder_output_i\n",
    "                decoder_input = torch.argmax(decoder_output_i, dim=-1)\n",
    "\n",
    "            return decoder_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2sec(\n",
       "  (encoder): EncoderGRU(\n",
       "    (gru): GRU(37, 32, batch_first=True)\n",
       "  )\n",
       "  (decoder): DecoderGRU(\n",
       "    (gru): GRU(14, 32, batch_first=True)\n",
       "    (fc): Linear(in_features=32, out_features=14, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Seq2sec(encoder, decoder)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 14])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_enc_batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(x_enc_batch, dec_input_batch = x_dec_batch, teacher_forcing = True).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
